# üê¶ Tweet Scraper via Nitter + Sentiment Analysis

Ce projet permet de **scraper des tweets publics** depuis [Nitter](https://nitter.net), une alternative sans JavaScript √† Twitter, et d'appliquer plusieurs **mod√®les d'analyse de sentiment**. Il est con√ßu pour contourner les limitations d'acc√®s via un syst√®me de **rotation de proxies HTTPS**.

## Objectif

- R√©cup√©rer quotidiennement des tweets li√©s √† une entreprise donn√©e (ex : `Tesla`).
- Appliquer 5 mod√®les de sentiment (VADER + 4 Transformers financiers).
- Sauvegarder les r√©sultats par mois et dans un fichier global, pour analyse de tendance ou backtest boursier.

---

## D√©pendances
```bash
pip install selenium webdriver-manager pandas langdetect beautifulsoup4 requests vaderSentiment transformers
```
Python 3.8+ recommand√©.

---

## Lancer le scraping

```bash
python main.py
```

Cela lance le scraping pour la plage de dates d√©finie dans `main.py`, par d√©faut entre le 15 et 19 avril 2025.

---

## Param√®tres configurables (`main.py`)
- `start_date` / `end_date` : plage de dates √† scraper
- `company_name` : mot-cl√© recherch√© dans les tweets (par d√©faut : "Tesla")
- `minimum_number_tweets_per_day` : nombre minimum de tweets √† collecter par jour

---

## üß© Fonctionnement (√©tapes principales)
1. **Initialisation des dates, mod√®les de sentiment et proxies**
2. **Pour chaque jour :**
   - Ouverture d'un navigateur avec proxy
   - Scraping sur Nitter
   - Nettoyage et filtrage des tweets en anglais
   - Analyse de sentiment avec VADER et 4 mod√®les Transformers
   - Enregistrement dans un buffer mensuel et global
3. **√Ä chaque changement de mois :**
   - √âcriture dans un fichier `Data_for_YYYY-MM.csv`
4. **√Ä la fin du script :**
   - Fusion et sauvegarde finale dans `Data_<company>.csv`

---

## Sch√©ma du processus de scraping (Mermaid)

```mermaid
graph TD
    Start[Start script] --> LoadParams[Load parameters]
    LoadParams --> LoopDates[Loop through dates]
    LoopDates --> GetProxy[Select valid proxy]
    GetProxy --> LaunchDriver[Init WebDriver with proxy]
    LaunchDriver --> AccessNitter[Access Nitter & search tweets]
    AccessNitter --> Extract[Extract & filter English tweets]
    Extract --> Clean[Clean tweet text]
    Clean --> Analyze[Sentiment analysis: VADER + models]
    Analyze --> MonthCheck{Month changed?}
    MonthCheck -- Yes --> SaveMonth[Save monthly CSV]
    MonthCheck -- No --> ContinueDate[Next date]
    SaveMonth --> ContinueDate
    ContinueDate --> FinalCheck{Last date?}
    FinalCheck -- No --> LoopDates
    FinalCheck -- Yes --> SaveAll[Save final CSV]
    SaveAll --> End[Done]
```

---

## Structure des fichiers

- `main.py` : script principal de scraping et orchestration
- `scrape.py` : logique de navigation sur Nitter, extraction des tweets
- `driver.py` : initialisation du navigateur Chrome avec proxy
- `utils.py` : g√©n√©ration de dates, gestion des proxies, nettoyage texte
- `sentiment.py` : analyse de sentiment avec VADER + Transformers

---

## Format de sortie

Les tweets sont sauvegard√©s dans :
- des fichiers mensuels : `Data_for_2025-04.csv`
- un fichier global : `Data_Tesla.csv`

Colonnes principales :
| id         | query_date | text               | verified | CLEANED_TWEET | SENTIMENT_VADER | SENTIMENT_ModelName |
|------------|------------|--------------------|----------|----------------|------------------|----------------------|
| tweet_id   | yyyy-mm-dd | contenu du tweet   | True/False | tweet nettoy√©  | score [-1 √† 1]   | score du mod√®le NLP  |

---

## Gestion des erreurs & contournement
- **Proxies HTTPS dynamiques** : R√©cup√©r√©s depuis `sslproxies.org` et filtr√©s en parall√®le pour ne garder que les proxies fonctionnels (`valid_proxies`).
- **Test parall√®le de validit√©** : Chaque proxy est test√© en parall√®le via une requ√™te HTTPS vers Nitter (`test_https_proxy`).
- **Rotation intelligente** : Un proxy est choisi al√©atoirement parmi les valides √† chaque tentative de scraping.
- **Retry quotidien** : Jusqu'√† 3 tentatives par jour avec changement de proxy entre chaque tentative.
- **Filtrage linguistique** : Seuls les tweets d√©tect√©s comme √©tant en anglais sont conserv√©s (`langdetect`).

---

## Contact
Pour toute am√©lioration ou suggestion, n'h√©site pas √† ouvrir une *issue* ou √† me contacter directement.

