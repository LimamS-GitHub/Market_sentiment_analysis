## ğŸ¤– Comprendre les Transformers

Les modÃ¨les utilisÃ©s dans notre analyse sont basÃ©s sur lâ€™architecture Transformer, une technologie rÃ©volutionnaire introduite en 2017 (Vaswani et al.).  
Contrairement aux RNNs ou LSTMs, ils traitent lâ€™ensemble dâ€™un texte en parallÃ¨le grÃ¢ce Ã  un mÃ©canisme dâ€™**attention**.

ğŸ‘‰ Pour une visualisation interactive de leur fonctionnement, nous vous recommandons cette ressource :

ğŸ”— [Transformer Visualizer (Polo Club)](https://poloclub.github.io/transformer-explainer/)

Dans notre projet, nous utilisons des versions spÃ©cialisÃ©es du Transformer, prÃ©entraÃ®nÃ©es sur des textes financiers (ex. : FinancialBERT, DeBERTa-v3-fin) pour analyser les tweets liÃ©s Ã  Tesla.

# ğŸ¤– Comment avons-nous utilisÃ© les Transformers ?

Les Transformers ont Ã©tÃ© utilisÃ©s pour **analyser le sentiment des tweets** que nous avons collectÃ©s au sujet de Tesla ($TSLA).  
Chaque tweet nettoyÃ© est passÃ© dans un ou plusieurs **modÃ¨les prÃ©-entraÃ®nÃ©s** pour dÃ©terminer sâ€™il exprime un avis positif, neutre ou nÃ©gatif.

---

## ğŸ”„ Ã‰tapes concrÃ¨tes d'utilisation

### 1. âœ… PrÃ©traitement des tweets

Avant dâ€™utiliser les modÃ¨les, chaque tweet est :

- **nettoyÃ©** : suppression des liens, mentions, hashtags, emojis, ponctuation ;
- **filtrÃ©** : seuls les tweets **en anglais** sont conservÃ©s (dÃ©tection automatique de langue).

Cela garantit une compatibilitÃ© optimale avec les modÃ¨les, tous entraÃ®nÃ©s sur des textes en anglais.

---

### 2. âœ… Analyse de sentiment par modÃ¨le Transformer

Chaque tweet propre est ensuite analysÃ© avec un modÃ¨le Transformer via `transformers.pipeline` (librairie Hugging Face).  
Le modÃ¨le retourne un **label** parmi :

- `POSITIVE` â†’ **+1**
- `NEUTRAL` â†’ **0**
- `NEGATIVE` â†’ **âˆ’1**

Ces scores sont utilisÃ©s pour Ã©valuer la tonalitÃ© du tweet et construire des indicateurs de marchÃ©.

---

### 3. âœ… ModÃ¨les utilisÃ©s

| ModÃ¨le HuggingFace                             | Architecture     | Domaine entraÃ®nÃ©                          | Utilisation principale                            |
|------------------------------------------------|------------------|--------------------------------------------|---------------------------------------------------|
| `ProsusAI/finbert`                             | BERT             | Documents financiers (10-K, actualitÃ©s)   | RÃ©fÃ©rence pour le sentiment boursier              |
| `Yiyang/deberta-v3-financial-news-sentiment`   | DeBERTa-v3       | News Ã©conomiques et financiÃ¨res           | Meilleure comprÃ©hension contextuelle              |
| `NbAiLab/distilroberta-financial-news-sentiment` | DistilRoBERTa | Articles de presse spÃ©cialisÃ©s finance    | LÃ©ger, rapide Ã  lâ€™infÃ©rence                       |

Chaque modÃ¨le attribue un score stockÃ© dans une colonne distincte (`sentiment_finbert`, `sentiment_deberta`, `sentiment_roberta`).

---

### 4. âœ… Structuration des rÃ©sultats

Ces scores sont ajoutÃ©s directement dans notre base de donnÃ©es finale (`tweets_with_sentiment.csv`) :

- Chaque ligne = 1 tweet + 3 scores de sentiment
- Permet ensuite une **agrÃ©gation journaliÃ¨re** et des calculs statistiques
- Sert de base Ã  la construction des signaux dans la stratÃ©gie de trading

---

## ğŸ¯ Pourquoi utiliser plusieurs modÃ¨les ?

Cela nous permet de :

- **Comparer les interprÃ©tations** de tweets parfois ambigus ;
- **Combiner plusieurs sources** pour lisser le bruit et amÃ©liorer la robustesse ;
- **Tester les performances de chaque modÃ¨le** dans notre pipeline de trading.

---

## ğŸ”— Pour mieux comprendre lâ€™architecture Transformer

Nous recommandons cette visualisation interactive :

ğŸ‘‰ [Transformer Visualizer â€“ Polo Club](https://poloclub.github.io/transformer-explainer/)

Elle montre comment les modÃ¨les attribuent de lâ€™importance Ã  chaque mot dans une phrase grÃ¢ce au mÃ©canisme dâ€™**attention**, cÅ“ur du fonctionnement des Transformers.

---

â¡ï¸ Partie suivante : [Analyse exploratoire du sentiment](analyse_sentiment.html)
