## ü§ñ Comprendre les Transformers

Les mod√®les utilis√©s dans notre analyse sont bas√©s sur l‚Äôarchitecture Transformer, une technologie r√©volutionnaire introduite en 2017 (Vaswani et al.).  
Contrairement aux RNNs ou LSTMs, ils traitent l‚Äôensemble d‚Äôun texte en parall√®le gr√¢ce √† un m√©canisme d‚Äô**attention**.

üëâ Pour une visualisation interactive de leur fonctionnement, nous vous recommandons cette ressource :

üîó [Transformer Visualizer (Polo Club)](https://poloclub.github.io/transformer-explainer/)

Dans notre projet, nous utilisons des versions sp√©cialis√©es du Transformer, pr√©entra√Æn√©es sur des textes financiers (ex. : FinancialBERT, DeBERTa-v3-fin) pour analyser les tweets li√©s √† Tesla.

# Explication de l'utilisation des mod√®les Transformers

Dans notre projet, les mod√®les Transformers ont √©t√© utilis√©s pour analyser le sentiment des tweets collect√©s au sujet de Tesla (TSLA).  
Chaque tweet a √©t√© pass√© dans un ou plusieurs mod√®les pr√©-entra√Æn√©s afin d'√©valuer s‚Äôil exprimait une opinion positive, neutre ou n√©gative.

---
## Sch√©ma de l‚Äôanalyse de sentiment avec Transformers

```mermaid
flowchart TD
  A[üóÇ Tweet brut] --> B[üîç Nettoyage du texte]
  B --> C[üåç D√©tection de la langue]
  C --> D{Langue = Anglais ?}
  D -- Oui --> E[üì§ Envoi au mod√®le Transformer]
  E --> F[üîé Pr√©diction : POS / NEU / NEG]
  F --> G[üìä Conversion : +1 / 0 / -1]
  G --> H[üìÑ Enregistrement dans CSV]
  D -- Non --> X[‚õî Tweet ignor√©]
  subgraph Mod√®les utilis√©s
    M1[FinBERT]
    M2[DeBERTa-v3-fin]
    M3[DistilRoBERTa-fin]
  end
  E --> M1 & M2 & M3



## √âtapes d'utilisation

### 1. Pr√©traitement des tweets

Avant de proc√©der √† l‚Äôanalyse de sentiment, nous avons appliqu√© un nettoyage des tweets afin de supprimer les √©l√©ments non informatifs : liens, mentions, hashtags, ponctuation, etc.  
Nous avons √©galement filtr√© les tweets par langue, en ne conservant que ceux r√©dig√©s en anglais.  
Ce choix s‚Äôexplique par le fait que tous les mod√®les utilis√©s ont √©t√© entra√Æn√©s sur des textes anglophones.

---

### 2. Application des mod√®les de sentiment

Une fois les tweets nettoy√©s, ils sont analys√©s √† l‚Äôaide de mod√®les de type Transformer.  
Ces mod√®les sont accessibles via l‚ÄôAPI `pipeline` de la biblioth√®que Hugging Face.  
Pour chaque tweet, le mod√®le renvoie un label de sentiment : `POSITIVE`, `NEUTRAL` ou `NEGATIVE`.

Nous avons ensuite converti ces labels en valeurs num√©riques pour faciliter leur traitement statistique :

- `POSITIVE` ‚Üí +1  
- `NEUTRAL` ‚Üí 0  
- `NEGATIVE` ‚Üí ‚àí1

---

### 3. Mod√®les utilis√©s

Nous avons utilis√© plusieurs mod√®les, tous sp√©cialis√©s dans le domaine financier. Cela permet d‚Äôobtenir des scores mieux adapt√©s au langage √©conomique souvent employ√© dans les tweets.

| Mod√®le | Architecture | Donn√©es d‚Äôentra√Ænement | Particularit√© |
|--------|--------------|------------------------|---------------|
| `ProsusAI/finbert` | BERT | Documents financiers et rapports annuels | R√©f√©rence en sentiment financier |
| `deberta-v3-financial-news-sentiment` | DeBERTa-v3 | Articles de presse boursiers | Bonne compr√©hension du contexte |
| `distilroberta-financial-news-sentiment` | DistilRoBERTa | Actualit√©s √©conomiques | Mod√®le l√©ger et rapide √† ex√©cuter |

Chaque mod√®le a √©t√© appliqu√© individuellement √† tous les tweets, et les r√©sultats sont enregistr√©s dans des colonnes distinctes (`sentiment_finbert`, `sentiment_deberta`, `sentiment_roberta`, etc.).

---

### 4. Int√©gration dans notre base de donn√©es

Les scores obtenus sont ajout√©s directement dans notre base structur√©e.  
Chaque tweet est donc enrichi de plusieurs indicateurs de sentiment.  
Ce jeu de donn√©es est ensuite utilis√© pour :

- construire des moyennes de sentiment par jour,
- explorer les corr√©lations avec les variations du cours de l'action Tesla,
- alimenter notre strat√©gie de trading.

---

## Pourquoi utiliser plusieurs mod√®les ?

Le choix d‚Äôutiliser plusieurs mod√®les repose sur plusieurs motivations :

- Les tweets sont souvent ambigus ou implicites. En comparant plusieurs scores, on peut rep√©rer les divergences ou convergences d‚Äôinterpr√©tation.
- En combinant les r√©sultats, on peut lisser les erreurs individuelles de chaque mod√®le.
- Cela permet √©galement de tester l‚Äôimpact de chaque mod√®le sur la performance globale de notre approche.

---

## Ressource pour mieux comprendre les Transformers

Pour mieux comprendre le fonctionnement des mod√®les Transformers et le principe de l'attention, nous recommandons la ressource suivante, particuli√®rement claire et interactive :

[Transformer Visualizer ‚Äì Polo Club](https://poloclub.github.io/transformer-explainer/)

Ce site illustre de mani√®re visuelle la fa√ßon dont les mots d‚Äôune phrase sont analys√©s et mis en relation les uns avec les autres dans un mod√®le Transformer.

---

Dans la section suivante, nous utiliserons ces scores pour explorer les liens entre sentiment agr√©g√© et performance boursi√®re.
